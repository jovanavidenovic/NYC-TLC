{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b1c0fe",
   "metadata": {},
   "source": [
    "### Big data course project\n",
    "<strong>T7: Forecasting demand for all services together</strong>\n",
    "\n",
    "Jovana Videnovic & Haris Kupinic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c5a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hostnamectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.dataframe as dd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "from datetime import timedelta\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "from dask_ml.ensemble import BlockwiseVotingRegressor\n",
    "import dask.array as da\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "from xgboost import dask as dxgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f1a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping(errors, n_iterations=1000):\n",
    "    \"\"\"Perform bootstrapping to estimate confidence intervals.\"\"\"\n",
    "    n_size = len(errors)\n",
    "    indices = np.random.randint(0, n_size, (n_iterations, n_size))\n",
    "    samples = errors[indices]\n",
    "    means = np.mean(samples, axis=1)\n",
    "    lower = np.percentile(means, 2.5)\n",
    "    upper = np.percentile(means, 97.5)\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5845696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=2, threads_per_worker=2, memory_limit='32GB')\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/d/hpc/home/jv8043/BD/project/T7/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9e5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_counts = pd.read_csv(data_path / \"daily_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_counts['pickup_datetime'] = pd.to_datetime(daily_counts['pickup_datetime'])\n",
    "daily_counts = daily_counts[(daily_counts[\"pickup_datetime\"] >= \"2019-03-01\") & (daily_counts[\"pickup_datetime\"] <= \"2024-12-31\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ffd20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"LGB\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e5fdec",
   "metadata": {},
   "source": [
    "### Minimal setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbdf9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(train_df, test_df, categorical_cols):\n",
    "    train_encoded = pd.get_dummies(train_df, columns=categorical_cols, drop_first=True)\n",
    "    test_encoded = pd.get_dummies(test_df, columns=categorical_cols, drop_first=True)\n",
    "    test_encoded = test_encoded.reindex(columns=train_encoded.columns, fill_value=0)\n",
    "    return train_encoded, test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbd60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4475d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(dt):\n",
    "    month = dt.month\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'summer'\n",
    "    else:\n",
    "        return 'autumn'\n",
    "\n",
    "daily_counts['pickup_datetime'] = pd.to_datetime(daily_counts['pickup_datetime'])\n",
    "daily_counts['season'] = daily_counts['pickup_datetime'].apply(get_season)\n",
    "daily_counts['day'] = daily_counts['pickup_datetime'].dt.day\n",
    "daily_counts['week_in_month'] = (daily_counts['pickup_datetime'].dt.day - 1) // 7 + 1\n",
    "daily_counts['day_of_year'] = daily_counts['pickup_datetime'].dt.dayofyear\n",
    "daily_counts['day_of_week'] = daily_counts['pickup_datetime'].dt.dayofweek\n",
    "daily_counts['year'] = daily_counts['pickup_datetime'].dt.year\n",
    "daily_counts['month'] = daily_counts['pickup_datetime'].dt.month\n",
    "daily_counts[\"weekend\"] = daily_counts[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "\n",
    "if \"GB\" not in MODEL_NAME:\n",
    "    daily_counts[\"day_of_week_sin\"] = np.sin(2 * np.pi * daily_counts[\"day_of_week\"] / 7)\n",
    "    daily_counts[\"day_of_week_cos\"] = np.cos(2 * np.pi * daily_counts[\"day_of_week\"] / 7)\n",
    "    daily_counts[\"month_sin\"] = np.sin(2 * np.pi * daily_counts[\"month\"] / 12)\n",
    "    daily_counts[\"month_cos\"] = np.cos(2 * np.pi * daily_counts[\"month\"] / 12)\n",
    "    daily_counts[\"day_of_year_sin\"] = np.sin(2 * np.pi * daily_counts[\"day_of_year\"] / 365)\n",
    "    daily_counts[\"day_of_year_cos\"] = np.cos(2 * np.pi * daily_counts[\"day_of_year\"] / 365)\n",
    "\n",
    "    del daily_counts[\"month\"]\n",
    "    del daily_counts['year']  \n",
    "\n",
    "daily_counts = daily_counts[daily_counts['ride_count'] > 1000]\n",
    "del daily_counts[\"pickup_datetime\"]\n",
    "del daily_counts[\"day_of_year\"]\n",
    "del daily_counts[\"day_of_week\"]\n",
    "\n",
    "train = daily_counts.iloc[:-test_size]\n",
    "test = daily_counts.iloc[-test_size:]\n",
    "\n",
    "if \"GB\" not in MODEL_NAME:\n",
    "    train, test = one_hot_encode(train, test, ['season'])\n",
    "else:\n",
    "    train, test = one_hot_encode(train, test, ['season', 'month', 'year'])\n",
    "    \n",
    "cols = train.columns.difference(['ride_count', 'pickup_datetime'])\n",
    "\n",
    "for c in cols:\n",
    "    train[c] = train[c].astype('float')\n",
    "    test[c] = test[c].astype('float')\n",
    "\n",
    "# Convert to Dask arrays\n",
    "# select all but 'ride_count' and 'pickup_datetime'\n",
    "X_train = da.from_array(train[cols].values)\n",
    "y_train = da.from_array(train['ride_count'].values)\n",
    "\n",
    "X_test = da.from_array(test[cols].values)\n",
    "y_test = da.from_array(test['ride_count'].values)\n",
    "\n",
    "\n",
    "if MODEL_NAME == \"DXGB\":\n",
    "    dtrain = dxgb.DaskDMatrix(client, X_train, y_train)\n",
    "    output = dxgb.train(\n",
    "        client,\n",
    "        {\"verbosity\": 2, \"tree_method\": \"hist\", \"objective\": \"reg:linear\"},\n",
    "        dtrain,\n",
    "        num_boost_round=4,\n",
    "        evals=[(dtrain, \"train\")],\n",
    ")    \n",
    "    prediction = dxgb.predict(client, output, X_test)\n",
    "    y_pred = prediction.compute()\n",
    "elif MODEL_NAME == \"XGB\":\n",
    "    est = dxgb.XGBRegressor()\n",
    "    est.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "    # Predict\n",
    "    y_pred = est.predict(X_test)\n",
    "elif MODEL_NAME == \"LGB\":\n",
    "    dask_model = lgb.DaskLGBMRegressor(client=client)\n",
    "    dask_model = dask_model.fit(X_train, y_train)\n",
    "    y_pred = dask_model.predict(X_test).compute()\n",
    "else:\n",
    "    est = BlockwiseVotingRegressor(\n",
    "        estimator= LinearRegression(),\n",
    "    )\n",
    "    # Fit the model\n",
    "    est.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = est.predict(X_test).compute()\n",
    "\n",
    "# Calculate and print metrics\n",
    "absolute_errors = np.abs(y_test.compute() - y_pred)\n",
    "lower, upper = bootstrapping(absolute_errors)\n",
    "\n",
    "print(f\"Lower bound: {lower}\")\n",
    "print(f\"Upper bound: {upper}\")\n",
    "print(\"MAE\", np.mean(absolute_errors))\n",
    "\n",
    "mape_errors = np.abs((y_test.compute() - y_pred) / y_test.compute())\n",
    "mape_lower, mape_upper = bootstrapping(mape_errors)\n",
    "\n",
    "print(f\"Lower bound: {mape_lower}\")\n",
    "print(f\"Upper bound: {mape_upper}\")\n",
    "print(\"MAPE\", np.mean(mape_errors))\n",
    "\n",
    "print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
