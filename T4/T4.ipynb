{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d51a246",
   "metadata": {},
   "source": [
    "### Big df course project\n",
    "<strong>T4: Initial EDA</strong>\n",
    "\n",
    "Jovana Videnovic & Haris Kupinic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7836f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import duckdb\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import time\n",
    "import dask.dataframe as dd\n",
    "import duckdb\n",
    "from dask_sql import Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e978bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf334990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "\n",
    "plt.rcParams['axes.facecolor']='w'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4a9225",
   "metadata": {},
   "source": [
    "### Loading the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36c22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_type = \"fhvhv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_dist_col = \"trip_distance\" if service_type != \"fhvhv\" else \"trip_miles\"\n",
    "fare_amount_col = \"fare_amount\" if service_type != \"fhvhv\" else \"driver_pay\"\n",
    "tip_amount_col = \"tip_amount\" if service_type != \"fhvhv\" else \"tips\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec812db",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_df_path = Path(\"/d/hpc/projects/FRI/bigdata/students/jv8043/partitioned_data\")\n",
    "vis_path = Path(\"/d/hpc/home/jv8043/BD/project/T4/T4_vis\") / service_type\n",
    "tables_path = Path(\"/d/hpc/home/jv8043/BD/project/T4/T4_tables\") / service_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fba6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(vis_path, exist_ok=True)\n",
    "os.makedirs(tables_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce8ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=4, threads_per_worker=1, memory_limit='32GB')\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0539a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet(part_df_path / service_type, engine=\"pyarrow\", assume_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaa424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 0.001% of the data\n",
    "df = df.sample(frac=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ca269",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of partitions:\", df.npartitions)\n",
    "nrows = df.shape[0].compute()\n",
    "print(\"Number of rows:\", nrows)\n",
    "print(\"Number of columns:\", len(df.columns))\n",
    "print(\"Column names:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone_lookup = pd.read_csv(\"/d/hpc/home/jv8043/BD/project/add_data/taxi_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba1fc6b",
   "metadata": {},
   "source": [
    "#### Starting EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f281683",
   "metadata": {},
   "source": [
    "<strong>Checking for missing values</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7eeec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_per_column = df.isna().sum()\n",
    "missing_per_column_result = missing_per_column.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846fcc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_per_column_percentage = round((missing_per_column_result / nrows) * 100, 2)\n",
    "# sort the results by percentage\n",
    "missing_per_column_percentage = missing_per_column_percentage.sort_values(ascending=False)\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_per_column_percentage)\n",
    "\n",
    "missing_per_column_percentage.to_csv(tables_path / \"missing_per_column.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5fe090",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"pickup_lat\", \"pickup_lon\", \"dropoff_lat\", \"dropoff_lon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b4de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows with missing values in the 'pickup_datetime' column or 'dropoff_datetime' column\n",
    "df = df.dropna(subset=['pickup_datetime', 'dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902d5d5e",
   "metadata": {},
   "source": [
    "<strong>Trip distance & duration analysis</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b22374",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of rides that lasted less than 1 minute:\", round(len(df[df[\"dropoff_datetime\"] - df[\"pickup_datetime\"] < pd.Timedelta(minutes=1)]) / len(df) * 100, 2), \"%\")\n",
    "print(\"Percentage of rides that lasted less than 5 minutes:\", round(len(df[df[\"dropoff_datetime\"] - df[\"pickup_datetime\"] < pd.Timedelta(minutes=5)]) / len(df) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0129dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of rides that lasted more than 60 minutes:\", round(len(df[df[\"dropoff_datetime\"] - df[\"pickup_datetime\"] > pd.Timedelta(minutes=60)]) / len(df) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aabc10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.sample(frac=0.01, random_state=42).copy()\n",
    "df_copy[\"trip_duration_mins\"] = (df[\"dropoff_datetime\"] - df[\"pickup_datetime\"]).dt.total_seconds() / 60\n",
    "df_copy[\"trip_duration_mins\"] = df_copy[\"trip_duration_mins\"].astype(int)\n",
    "df_copy = df_copy[df_copy[\"trip_duration_mins\"] <= 60]\n",
    "df_copy = df_copy[df_copy[\"trip_duration_mins\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[\"duration_bin\"] = (df_copy[\"trip_duration_mins\"] // 10) * 10\n",
    "df_copy[\"duration_bin\"] = df_copy[\"duration_bin\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10e9abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip for now\n",
    "# # Group by duration bin label and count\n",
    "# bin_counts = df_copy[[\"duration_bin\"]].dropna().compute()\n",
    "# # Compute total number of rows for percentage calculation\n",
    "# total_count = len(bin_counts)\n",
    "\n",
    "# bin_counts = bin_counts[\"duration_bin\"].value_counts()\n",
    "\n",
    "# # Compute both\n",
    "# bin_counts = bin_counts\n",
    "# total_count = total_count\n",
    "\n",
    "# # Calculate percentage\n",
    "# bin_percentages = (bin_counts / total_count) * 100\n",
    "\n",
    "# # Print sorted by bin\n",
    "# bin_percentages = bin_percentages.sort_index()\n",
    "# print(bin_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747dbb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip for now\n",
    "# fig, ax = plt.subplots(figsize=(6, 3))\n",
    "# ax.bar(bin_percentages.index.astype(str), bin_percentages.values, color='salmon', edgecolor='black')\n",
    "\n",
    "# ax.set_xlabel(\"Duration (min)\")\n",
    "# ax.set_ylabel(\"Rides (%)\")\n",
    "# ax.set_xticklabels(bin_percentages.index.astype(str), rotation=45, ha='right')\n",
    "\n",
    "# for sp in [\"left\", \"bottom\"]:\n",
    "#     ax.spines[sp].set_color('0.5')\n",
    "\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "\n",
    "# # annotate the percentage on top of each bar\n",
    "# for i, v in enumerate(bin_percentages.values):\n",
    "#     ax.text(i, v + 0.5, f\"{v:.2f}%\", ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(vis_path / \"duration_bins_percentage.pdf\", dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if service_type not in [\"fhv\"]:\n",
    "    # Compute average and std of trip_distance\n",
    "    \n",
    "    trip_distance_mean = df[trip_dist_col].mean().compute()\n",
    "    trip_distance_std = df[trip_dist_col].std().compute()\n",
    "\n",
    "    print(\"Average trip distance, STD:\", round(trip_distance_mean, 2), round(trip_distance_std, 2), \"miles\")\n",
    "\n",
    "# Compute trip duration in minutes\n",
    "trip_duration = (df[\"dropoff_datetime\"] - df[\"pickup_datetime\"]).dt.total_seconds() / 60\n",
    "\n",
    "trip_duration_mean = trip_duration.mean().compute()\n",
    "trip_duration_std = trip_duration.std().compute()\n",
    "\n",
    "print(\"Average trip duration, STD:\", round(trip_duration_mean, 2), round(trip_duration_std, 2), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ac86cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if service_type not in [\"fhv\"]:\n",
    "    # Filter only trips with distance <= 200 miles and those with pulocationid and dolocationid not null\n",
    "    df_copy = df[\n",
    "        (df[trip_dist_col] <= 200) &\n",
    "        (~df[\"pulocationid\"].isin([264, 265])) &\n",
    "        (~df[\"dolocationid\"].isin([264, 265]))\n",
    "    ].copy()\n",
    "\n",
    "    # Compute the top 1% of trips by trip distance\n",
    "    top_1_percent_threshold = df_copy[trip_dist_col].quantile(0.99).compute()\n",
    "    print(\"Top 1% trip distance threshold:\", round(top_1_percent_threshold, 2), \"miles\")\n",
    "    top_1_percent_trips = df_copy[df_copy[trip_dist_col] >= top_1_percent_threshold]\n",
    "\n",
    "    # Join with taxi zone lookup for pickup zone\n",
    "    top_1_percent_trips = top_1_percent_trips.merge(\n",
    "        taxi_zone_lookup,\n",
    "        left_on=\"pulocationid\",\n",
    "        right_on=\"LocationID\",\n",
    "        how=\"left\"\n",
    "    ).rename(columns={\"Zone\": \"pickup_zone\"})\n",
    "\n",
    "    # Join with taxi zone lookup for dropoff zone\n",
    "    top_1_percent_trips = top_1_percent_trips.merge(\n",
    "        taxi_zone_lookup,\n",
    "        left_on=\"dolocationid\",\n",
    "        right_on=\"LocationID\",\n",
    "        how=\"left\"\n",
    "    ).rename(columns={\"Zone\": \"dropoff_zone\"})\n",
    "\n",
    "    # Select and reorder relevant columns\n",
    "    top_1_percent_trips = top_1_percent_trips[[\n",
    "        \"pickup_zone\", \"dropoff_zone\", trip_dist_col,\n",
    "        \"pickup_datetime\", \"dropoff_datetime\"\n",
    "    ]]\n",
    "\n",
    "    # Sort and reset index after computing\n",
    "    top_1_percent_trips = top_1_percent_trips.compute()\n",
    "    top_1_percent_trips = top_1_percent_trips.sort_values(\n",
    "        by=trip_dist_col, ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # Select columns to display\n",
    "    top_1_percent_trips = top_1_percent_trips[[\"pickup_zone\", \"dropoff_zone\", trip_dist_col]]\n",
    "\n",
    "    # Show top 10\n",
    "    display(top_1_percent_trips)\n",
    "    # Save the top 1% trips to a CSV file\n",
    "    top_1_percent_trips.to_csv(tables_path / \"top_1_percent_trips.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dabad0",
   "metadata": {},
   "source": [
    "<strong>Fare amount analysis</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get avg tip amount\n",
    "avg_tip_amount = df[tip_amount_col].mean().compute()\n",
    "print(\"Average tip amount\", avg_tip_amount, \"$\")\n",
    "# Get avg fare amount\n",
    "avg_fare_amount = df[fare_amount_col].mean().compute()\n",
    "print(\"Average fare amount\", avg_fare_amount, \"$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5304d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lowest / highest 1% of fare amount:\", round(df[fare_amount_col].quantile(0.01).compute()), \"$ /\", round(df[fare_amount_col].quantile(0.99).compute()), \"$\")\n",
    "print(\"Highest fare amount:\", round(df[fare_amount_col].max().compute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = df.copy().sample(frac=0.0001, random_state=42)\n",
    "\n",
    "# Apply filters\n",
    "data_ = data_[\n",
    "    (data_[fare_amount_col] >= 0) &\n",
    "    (data_[fare_amount_col] <= 100) &\n",
    "    (data_[trip_dist_col] >= 0) &\n",
    "    (data_[trip_dist_col] <= 31)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab27f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in fare_amount or trip_distance\n",
    "data_ = data_.dropna(subset=[fare_amount_col, trip_dist_col])\n",
    "\n",
    "# Sample and compute to pandas\n",
    "data_pd = data_[[trip_dist_col, fare_amount_col]].compute()\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.scatter(data_pd[trip_dist_col], data_pd[fare_amount_col], alpha=0.5, color='salmon', s=1, rasterized=True)\n",
    "ax.set_xlabel(\"Trip distance (miles)\")\n",
    "ax.set_ylabel(\"Fare amount ($)\")\n",
    "ax.spines['left'].set_color('0.5')\n",
    "ax.spines['bottom'].set_color('0.5')\n",
    "ax.set_title(service_type.capitalize())\n",
    "fig.tight_layout()\n",
    "fig.savefig(vis_path / \"scatter_trip_distance_fare.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cca7dd",
   "metadata": {},
   "source": [
    "##### Temporal aggregation\n",
    "\n",
    "In this part, we perform temporal aggregation on pickup or dropoff times. We first analyse rides distribution per pickup and dropoff time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f14173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy data\n",
    "data_ = df.copy()\n",
    "\n",
    "# Extract pickup and dropoff hour (0–23)\n",
    "data_[\"pickup_hour\"] = data_[\"pickup_datetime\"].dt.hour\n",
    "data_[\"dropoff_hour\"] = data_[\"dropoff_datetime\"].dt.hour\n",
    "\n",
    "# Compute value counts\n",
    "pickup_counts = data_[\"pickup_hour\"].value_counts().compute().sort_index()\n",
    "dropoff_counts = data_[\"dropoff_hour\"].value_counts().compute().sort_index()\n",
    "\n",
    "# Convert counts to percentages\n",
    "pickup_percent = (pickup_counts / pickup_counts.sum()) * 100\n",
    "dropoff_percent = (dropoff_counts / dropoff_counts.sum()) * 100\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "\n",
    "# Pickup plot\n",
    "axs[0].bar(pickup_percent.index, pickup_percent.values, color='salmon', edgecolor='black')\n",
    "axs[0].set_xlabel(\"Pickup hour\")\n",
    "axs[0].set_ylabel(\"Percentage of rides (%)\")\n",
    "axs[0].set_xticks(range(24))\n",
    "axs[0].set_xticklabels([f\"{h:02d}\" for h in range(24)], rotation=45, ha='right')\n",
    "axs[0].set_title(\"Pickup time distribution\")\n",
    "\n",
    "# Dropoff plot\n",
    "axs[1].bar(dropoff_percent.index, dropoff_percent.values, color='salmon', edgecolor='black')\n",
    "axs[1].set_xlabel(\"Dropoff hour\")\n",
    "axs[1].set_xticks(range(24))\n",
    "axs[1].set_xticklabels([f\"{h:02d}\" for h in range(24)], rotation=45, ha='right')\n",
    "axs[1].set_title(\"Dropoff time distribution\")\n",
    "\n",
    "# Style\n",
    "for ax in axs:\n",
    "    for sp in [\"left\", \"bottom\"]:\n",
    "        ax.spines[sp].set_color('0.5')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(vis_path / \"pickup_dropoff_hour_distribution.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64724ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the Dask DataFrame\n",
    "data_ = df.copy()\n",
    "\n",
    "# Extract pickup and dropoff hour (0–23)\n",
    "data_[\"pickup_hour\"] = data_[\"pickup_datetime\"].dt.hour\n",
    "data_[\"dropoff_hour\"] = data_[\"dropoff_datetime\"].dt.hour\n",
    "\n",
    "# Group by pickup hour\n",
    "median_distance_pickup = data_.groupby(\"pickup_hour\")[trip_dist_col].median().compute()\n",
    "pickup_counts = data_[\"pickup_hour\"].value_counts().compute().sort_index()\n",
    "\n",
    "# Group by dropoff hour\n",
    "median_distance_dropoff = data_.groupby(\"dropoff_hour\")[trip_dist_col].median().compute()\n",
    "dropoff_counts = data_[\"dropoff_hour\"].value_counts().compute().sort_index()\n",
    "\n",
    "# Convert counts to percentages\n",
    "pickup_percentages = (pickup_counts / pickup_counts.sum()) * 100\n",
    "dropoff_percentages = (dropoff_counts / dropoff_counts.sum()) * 100\n",
    "\n",
    "# Sort by hour\n",
    "median_distance_pickup = median_distance_pickup.sort_index()\n",
    "median_distance_dropoff = median_distance_dropoff.sort_index()\n",
    "pickup_percentages = pickup_percentages.sort_index()\n",
    "dropoff_percentages = dropoff_percentages.sort_index()\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(11, 4), sharey=True)\n",
    "\n",
    "# Pickup plot\n",
    "ax = axs[0]\n",
    "median_distance_pickup.plot(kind='line', marker='o', ax=ax, color='salmon')\n",
    "ax.set_xlabel(\"Pickup hour\")\n",
    "ax.set_ylabel(\"Median trip distance (miles)\")\n",
    "ax.set_xticks(range(24))\n",
    "ax.set_xticklabels([f\"{h:02d}\" for h in range(24)], rotation=45, ha='right')\n",
    "# show with dotted line also median overall from all the data\n",
    "trip_overall_median = data_[trip_dist_col].median_approximate().compute()\n",
    "ax.axhline(trip_overall_median, color='gray', linestyle='--', label='Overall median')\n",
    "ax.legend()\n",
    "\n",
    "# for i, (val, pct) in enumerate(zip(median_distance_pickup, pickup_percentages)):\n",
    "#     ax.annotate(f\"{pct:.1f}%\", (i, val), textcoords=\"offset points\", xytext=(0, 6), ha='center', fontsize=8)\n",
    "\n",
    "# Dropoff plot\n",
    "ax = axs[1]\n",
    "median_distance_dropoff.plot(kind='line', marker='o', ax=ax, color='salmon')\n",
    "ax.set_xlabel(\"Dropoff hour\")\n",
    "ax.set_xticks(range(24))\n",
    "ax.set_xticklabels([f\"{h:02d}\" for h in range(24)], rotation=45, ha='right')\n",
    "# for i, (val, pct) in enumerate(zip(median_distance_dropoff, dropoff_percentages)):\n",
    "#     ax.annotate(f\"{pct:.1f}%\", (i, val), textcoords=\"offset points\", xytext=(0, 6), ha='center', fontsize=8)\n",
    "# show with dotted line also median overall from all the data\n",
    "ax.axhline(trip_overall_median, color='gray', linestyle='--', label='Overall median')\n",
    "ax.legend()\n",
    "\n",
    "# Style\n",
    "for ax in axs:\n",
    "    for sp in [\"left\", \"bottom\"]:\n",
    "        ax.spines[sp].set_color('0.5')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(vis_path / \"median_trip_distance_by_hour.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23335f63",
   "metadata": {},
   "source": [
    "##### Spatial aggregation\n",
    "\n",
    "Next, we do spatial aggregation, by pickup and dropoff location taxi zone. We show it directly on NYC map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711f864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = df.copy()\n",
    "\n",
    "# Merge with taxi_zone_lookup to get pickup zone\n",
    "data_ = data_.merge(taxi_zone_lookup, left_on=\"pulocationid\", right_on=\"LocationID\", how=\"left\")\n",
    "data_ = data_.rename(columns={\"Zone\": \"pickup_zone\"}).drop(\"LocationID\", axis=1)\n",
    "\n",
    "# Merge again to get dropoff zone\n",
    "data_ = data_.merge(taxi_zone_lookup, left_on=\"dolocationid\", right_on=\"LocationID\", how=\"left\")\n",
    "data_ = data_.rename(columns={\"Zone\": \"dropoff_zone\"}).drop(\"LocationID\", axis=1)\n",
    "\n",
    "# Select relevant columns\n",
    "data_ = data_[[\"pickup_zone\", \"dropoff_zone\", trip_dist_col, \"pickup_datetime\", \"dropoff_datetime\"]]\n",
    "\n",
    "# Sort by trip_distance\n",
    "sampled = data_.compute() \n",
    "sampled = sampled.sort_values(by=trip_dist_col, ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Show top 1\n",
    "display(sampled.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db479f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count pickups and dropoffs by zone\n",
    "pickup_counts = data_[\"pickup_zone\"].value_counts()\n",
    "dropoff_counts = data_[\"dropoff_zone\"].value_counts()\n",
    "\n",
    "# Compute them (convert to pandas)\n",
    "pickup_counts = pickup_counts.compute()\n",
    "dropoff_counts = dropoff_counts.compute()\n",
    "\n",
    "# Normalize to percentages\n",
    "pickup_percentages = (pickup_counts / pickup_counts.sum()) * 100\n",
    "dropoff_percentages = (dropoff_counts / dropoff_counts.sum()) * 100\n",
    "\n",
    "# Get top zones and percentages\n",
    "top_pickup_zone = pickup_percentages.idxmax()\n",
    "top_pickup_pct = round(pickup_percentages.max(), 2)\n",
    "\n",
    "top_dropoff_zone = dropoff_percentages.idxmax()\n",
    "top_dropoff_pct = round(dropoff_percentages.max(), 2)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Locations with the most pickups and dropoffs: {top_pickup_zone} ({top_pickup_pct}%) / {top_dropoff_zone} ({top_dropoff_pct}%).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top 5 pickup zones and dropoff zones\n",
    "# first sort the percentages\n",
    "pickup_percentages = pickup_percentages.sort_values(ascending=False)\n",
    "dropoff_percentages = dropoff_percentages.sort_values(ascending=False)\n",
    "print(\"Top 5 pickup zones:\")\n",
    "display(pickup_percentages.head(5))\n",
    "print(\"Top 5 dropoff zones:\")\n",
    "display(dropoff_percentages.head(5))\n",
    "\n",
    "# Save the pickup and dropoff zone percentages to CSV files\n",
    "pickup_percentages.to_csv(tables_path / \"pickup_zone_percentages.csv\", header=True, index=True)\n",
    "dropoff_percentages.to_csv(tables_path / \"dropoff_zone_percentages.csv\", header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a6ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dask copy\n",
    "data_ = df.copy()\n",
    "\n",
    "# Compute pickup counts\n",
    "pickup_counts = data_['pulocationid'].value_counts().compute().reset_index()\n",
    "pickup_counts.columns = ['LocationID', 'pickup_count']\n",
    "total_pickups = pickup_counts['pickup_count'].sum()\n",
    "pickup_counts['pickup_percent'] = 100 * pickup_counts['pickup_count'] / total_pickups\n",
    "\n",
    "# Compute dropoff counts\n",
    "dropoff_counts = data_['dolocationid'].value_counts().compute().reset_index()\n",
    "dropoff_counts.columns = ['LocationID', 'dropoff_count']\n",
    "total_dropoffs = dropoff_counts['dropoff_count'].sum()\n",
    "dropoff_counts['dropoff_percent'] = 100 * dropoff_counts['dropoff_count'] / total_dropoffs\n",
    "\n",
    "# Load taxi zones shapefile\n",
    "zones = gpd.read_file(\"/d/hpc/home/jv8043/BD/project/T4/taxi_zones.shp\")\n",
    "zones[\"LocationID\"] = zones[\"LocationID\"].astype(int)\n",
    "\n",
    "# Merge pickup and dropoff percentages\n",
    "zones = zones.merge(pickup_counts[['LocationID', 'pickup_percent']], on=\"LocationID\", how=\"left\")\n",
    "zones = zones.merge(dropoff_counts[['LocationID', 'dropoff_percent']], on=\"LocationID\", how=\"left\")\n",
    "\n",
    "# Filter to Manhattan and Harlem\n",
    "# manhattan_zones = zones[zones['borough'].str.upper().isin([\"MANHATTAN\", \"HARLEM\"])]\n",
    "\n",
    "if service_type in [\"green\", \"fhv\", \"fhvhv\"]:\n",
    "    zones = zones[zones['borough'].str.upper().isin([\"MANHATTAN\", \"HARLEM\", \"BROOKLYN\", \"QUEENS\"])]\n",
    "elif service_type == \"yellow\":\n",
    "    zones = zones[zones['borough'].str.upper().isin([\"MANHATTAN\", \"HARLEM\"])]\n",
    "\n",
    "# Shared color scale range\n",
    "vmin = 0\n",
    "vmax = max(\n",
    "    zones['pickup_percent'].max(),\n",
    "    zones['dropoff_percent'].max()\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "# Pickup heatmap\n",
    "pickup_ax = axs[0]\n",
    "pickup_plot = zones.plot(\n",
    "    column=\"pickup_percent\",\n",
    "    cmap=\"OrRd\",\n",
    "    linewidth=0.5,\n",
    "    edgecolor=\"black\",\n",
    "    legend=False,\n",
    "    ax=pickup_ax,\n",
    "    missing_kwds={\"color\": \"lightgrey\", \"label\": \"No data\"},\n",
    "    vmin=vmin,\n",
    "    vmax=vmax\n",
    ")\n",
    "pickup_ax.set_title(\"Pickup Percentage\", fontsize=14)\n",
    "pickup_ax.axis(\"off\")\n",
    "\n",
    "# Dropoff heatmap\n",
    "dropoff_ax = axs[1]\n",
    "dropoff_plot = zones.plot(\n",
    "    column=\"dropoff_percent\",\n",
    "    cmap=\"OrRd\",\n",
    "    linewidth=0.5,\n",
    "    edgecolor=\"black\",\n",
    "    legend=False,\n",
    "    ax=dropoff_ax,\n",
    "    missing_kwds={\"color\": \"lightgrey\", \"label\": \"No data\"},\n",
    "    vmin=vmin,\n",
    "    vmax=vmax\n",
    ")\n",
    "dropoff_ax.set_title(\"Dropoff Percentage\", fontsize=14)\n",
    "dropoff_ax.axis(\"off\")\n",
    "\n",
    "# Add shared colorbar\n",
    "fig.colorbar(dropoff_plot.get_children()[0], ax=dropoff_ax, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(vis_path / \"pickup_dropoff_heatmap.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a7902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and filter using Dask\n",
    "data_ = df.copy()\n",
    "fare_threshold = data_[fare_amount_col].quantile(0.95).compute()\n",
    "data_ = data_[data_[fare_amount_col] < fare_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa4415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by and compute median using Dask, then convert to pandas\n",
    "pickup_median_fare = data_.groupby('pulocationid')[fare_amount_col].median().compute().reset_index(name='pickup_median_fare')\n",
    "dropoff_median_fare = data_.groupby('dolocationid')[fare_amount_col].median().compute().reset_index(name='dropoff_median_fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c991a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read shapefile with GeoPandas\n",
    "zones = gpd.read_file(\"/d/hpc/home/jv8043/BD/project/T4/taxi_zones.shp\")\n",
    "zones[\"LocationID\"] = zones[\"LocationID\"].astype(int)\n",
    "\n",
    "# Merge with pickup and dropoff median fares\n",
    "zones = zones.merge(pickup_median_fare, left_on='LocationID', right_on='pulocationid', how='left')\n",
    "zones = zones.merge(dropoff_median_fare, left_on='LocationID', right_on='dolocationid', how='left')\n",
    "\n",
    "# Filter to Manhattan and Harlem\n",
    "# manhattan_zones = zones[zones['borough'].str.upper().isin([\"MANHATTAN\", \"HARLEM\"])]\n",
    "if service_type in [\"green\", \"fhv\", \"fhvhv\"]:\n",
    "    zones = zones[zones['borough'].str.upper().isin([\"MANHATTAN\", \"HARLEM\", \"BROOKLYN\", \"QUEENS\"])]\n",
    "elif service_type == \"yellow\":\n",
    "    zones = zones[zones['borough'].str.upper().isin([\"MANHATTAN\", \"HARLEM\"])]\n",
    "\n",
    "# Define color scale\n",
    "vmin = min(zones['pickup_median_fare'].min(), zones['dropoff_median_fare'].min())\n",
    "vmax = max(zones['pickup_median_fare'].max(), zones['dropoff_median_fare'].max())\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "# Pickup\n",
    "ax = axs[0]\n",
    "pickup_plot = zones.plot(column=\"pickup_median_fare\", cmap=\"OrRd\", linewidth=0.5, edgecolor=\"black\",\n",
    "                                   legend=False, ax=ax, missing_kwds={\"color\": \"lightgrey\", \"label\": \"No data\"},\n",
    "                                   vmin=vmin, vmax=vmax)\n",
    "ax.set_title(\"Median fare per pickup zone\", fontsize=14)\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Dropoff\n",
    "ax = axs[1]\n",
    "dropoff_plot = zones.plot(column=\"dropoff_median_fare\", cmap=\"OrRd\", linewidth=0.5, edgecolor=\"black\",\n",
    "                                    legend=False, ax=ax, missing_kwds={\"color\": \"lightgrey\", \"label\": \"No data\"},\n",
    "                                    vmin=vmin, vmax=vmax)\n",
    "ax.set_title(\"Median fare per dropoff zone\", fontsize=14)\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Shared colorbar\n",
    "fig.colorbar(dropoff_plot.get_children()[0], ax=ax, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "fig.tight_layout()\n",
    "fig.savefig(vis_path / \"pickup_dropoff_median_fare.pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown the Dask client and cluster\n",
    "client.shutdown()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
